{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92a5583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from gan import Generator, Discriminator, GAN\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import pdb\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db250ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# instantiate generator\n",
    "generator = Generator()\n",
    "\n",
    "# instantiate discriminator (pre-trained facial recognition model)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# construct GAN network in full\n",
    "gan = GAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "848c3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unmasked faces from FFHQ\n",
    "num_faces = 10\n",
    "unmasked_faces = torch.zeros((num_faces, 3, 128, 128))\n",
    "mtcnn = MTCNN(image_size=128)\n",
    "for face_id in range(num_faces):\n",
    "    face_id_text = str(100000 + face_id)[1:]\n",
    "    image_path = '../data/unmasked/{}.png'.format(face_id_text)\n",
    "    face_image = mtcnn(Image.open(image_path))\n",
    "    unmasked_faces[face_id] = face_image\n",
    "    \n",
    "# compute and store unmasked discriminator embeddings\n",
    "gan.compute_unmasked_embeddings(unmasked_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a49523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load masked faces from MaskedNet\n",
    "masked_faces = torch.zeros((num_faces, 3, 128, 128))\n",
    "mtcnn = MTCNN(image_size=128)\n",
    "for face_id in range(num_faces):\n",
    "    face_id_text = str(100000 + face_id)[1:]\n",
    "    image_path = '../data/masked/{}_Mask.jpg'.format(face_id_text)\n",
    "    face_image = mtcnn(Image.open(image_path))\n",
    "    masked_faces[face_id] = face_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train CycleGAN for projecting mask designs onto faces\n",
    "# load_path = None\n",
    "projector = CycleGAN()\n",
    "projector.train(num_epochs=10, faces=masked_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce31e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # sort data into minibatches\n",
    "    minibatches = batch_data()\n",
    "    \n",
    "    # train on each minibatch\n",
    "    for batch in minibatch:\n",
    "        # get data\n",
    "        faces, ids = batch\n",
    "    \n",
    "        # generate mask design\n",
    "        mask = gan.generator()\n",
    "    \n",
    "        # project design onto masked images\n",
    "        faces = gan.project(mask, faces)\n",
    "        \n",
    "        # "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
